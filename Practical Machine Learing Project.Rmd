---
title: "Practical Machine Learning Course Project"
author: "Sunil Samson S"
date: "10/16/2020"
output: html_document
---
## Overview
Utilizing gadgets, for example, Jawbone Up, Nike FuelBand, and Fitbit it is presently conceivable to gather a lot of information about personal activity at very low cost. These sort of gadgets are important to evaluate self development â€“ a gathering of fans who take estimations about themselves consistently to improve their personal wellbeing, to discover designs in their conduct, or in light of the fact that they are tech nerds. One thing that individuals routinely do is evaluate the amount of a specific action they do, yet they seldom measure how well they do it. 
In this undertaking, we will utilize information from accelerometers on the belt, lower arm, arm, and dumbell of 6 members to anticipate the way in which they did the activity.

## Data Pre-Processing
```{r}
library(caret)
library(rpart)
library(rpart.plot)
library(randomForest)
library(corrplot)
```

## Downloading Data
```{r}
trainUrl <-"https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
testUrl <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
trainFile <- "./data/pml-training.csv"
testFile  <- "./data/pml-testing.csv"
if (!file.exists("./data")) {
  dir.create("./data")
}
if (!file.exists(trainFile)) {
  download.file(trainUrl, destfile=trainFile, method="curl")
}
if (!file.exists(testFile)) {
  download.file(testUrl, destfile=testFile, method="curl")
}
```

## Reading the Data 
Once the data is downloaded from the website, read the data into 2 dataframes namely train and test. 
```{r}
trainData <- read.csv("./data/pml-training.csv")
testData <- read.csv("./data/pml-testing.csv")
dim(trainData)
dim(testData)
```

## Data Cleaning
Data cleaning is used to avoid the problems that arises due to missing values.
```{r}
sum(complete.cases(trainData))
```

Removing columns that have missing values.
```{r}
trainData <- trainData[, colSums(is.na(trainData)) == 0] 
testData <- testData[, colSums(is.na(testData)) == 0] 
```

Removing data which are meaningless to the measurements of the accelerometer
```{r}
classe <- trainData$classe
train_Removed <- grepl("^X|timestamp|window", names(trainData))
trainData <- trainData[, !train_Removed]
train_Clean <- trainData[, sapply(trainData, is.numeric)]
train_Clean$classe <- classe
test_Removed <- grepl("^X|timestamp|window", names(testData))
testData <- testData[, !test_Removed]
test_Clean <- testData[, sapply(testData, is.numeric)]
```

## Data Splitting
Split the data in training set (70%) and testing set (30%).
```{r}
set.seed(21162)
inTrain <- createDataPartition(train_Clean$classe, p=0.70, list=F)
train_Data <- train_Clean[inTrain, ]
test_Data <- train_Clean[-inTrain, ]
```

## Data Modelling
```{r}
controlRf <- trainControl(method="cv", 5)
modelRf <- train(classe ~ ., data=train_Data, method="rf", trControl=controlRf, ntree=250)
modelRf
```

Now, evaluate the model performance on the test data.

```{r}
predictRf <- predict(modelRf, test_Data)
confusionMatrix(test_Data$classe, predictRf)
```

```{r}
accuracy <- postResample(predictRf, test_Data$classe)
accuracy
oose <- 1 - as.numeric(confusionMatrix(test_Data$classe, predictRf)$overall[1])
oose
```

## Precicting for test data.
Using the model on the actual test data set.
```{r}
result <- predict(modelRf, test_Clean[, -length(names(test_Clean))])
result
```


## Visualization 

1.Matrix Visualization  
```{r}
corrPlot <- cor(train_Data[, -length(names(train_Data))])
corrplot(corrPlot, method="color")
```

2. Decision Tree
```{r}
treeModel <- rpart(classe ~ ., data=train_Data, method="class")
prp(treeModel)
```

